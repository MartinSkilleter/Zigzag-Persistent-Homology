{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "np.random.seed(17)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cluster_r_size = 50\n",
    "cluster_b_size = 50\n",
    "wide_bridge_size = 3\n",
    "\n",
    "number_of_cascades = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "#Generate the base graph with two clusters the wide bridge and no attachments\n",
    "\n",
    "sg1 = nx.powerlaw_cluster_graph(cluster_r_size, 3, 0.05, seed=seed)\n",
    "nx.set_node_attributes(sg1, 'r', 'color')\n",
    "\n",
    "sg2 = nx.powerlaw_cluster_graph(cluster_b_size, 3, 0.05, seed=seed)\n",
    "nx.set_node_attributes(sg2, 'b', 'color')\n",
    "sg2 = nx.relabel_nodes(sg2, {i:i + cluster_r_size for i in range(cluster_b_size)})\n",
    "\n",
    "sgWB = nx.Graph()\n",
    "sgWB.add_nodes_from(range(cluster_r_size+cluster_b_size,cluster_r_size+cluster_b_size + wide_bridge_size))\n",
    "nx.set_node_attributes(sgWB, 'g', 'color')\n",
    "\n",
    "sg = nx.compose(sg1, sg2)\n",
    "sg = nx.compose(sg, sgWB)\n",
    "colors_1 = [sg.nodes[n]['color'] for n in sg.nodes()]\n",
    "\n",
    "# Generate a basic attachment\n",
    "sg_1 = sg.copy()\n",
    "cluster_r_size = 50\n",
    "cluster_b_size = 50\n",
    "wide_bridge_size = 3\n",
    "for i in range(cluster_b_size+cluster_r_size,cluster_b_size+cluster_r_size+wide_bridge_size):\n",
    "    sg_1.add_edge(np.random.randint(cluster_r_size),i)\n",
    "    sg_1.add_edge(cluster_r_size+np.random.randint(cluster_b_size),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a complex attachment\n",
    "\n",
    "# Use an geometric distribution to determine how many targets in each cluster to attach to\n",
    "# Use a preferential attachment distribution over the cluster to determine which get attachments\n",
    "# Have wide bridge connectors connect to eachother with bernoulli dist\n",
    "\n",
    "def generate_graph_with_attachments(attachment_number_mean = 1, inter_bridge_connection_prob =  0.05, cluster_r_size = 50,cluster_b_size = 50, wide_bridge_size = 3):\n",
    "    sg1 = nx.powerlaw_cluster_graph(cluster_r_size, 3, 0.05, seed=seed)\n",
    "    nx.set_node_attributes(sg1, 'r', 'color')\n",
    "\n",
    "    sg2 = nx.powerlaw_cluster_graph(cluster_b_size, 3, 0.05, seed=seed)\n",
    "    nx.set_node_attributes(sg2, 'b', 'color')\n",
    "    sg2 = nx.relabel_nodes(sg2, {i:i + cluster_r_size for i in range(cluster_b_size)})\n",
    "\n",
    "    sgWB = nx.Graph()\n",
    "    sgWB.add_nodes_from(range(cluster_r_size+cluster_b_size,cluster_r_size+cluster_b_size + wide_bridge_size))\n",
    "    nx.set_node_attributes(sgWB, 'g', 'color')\n",
    "\n",
    "    sg = nx.compose(sg1, sg2)\n",
    "    sg = nx.compose(sg, sgWB)\n",
    "    colors = [sg.nodes[n]['color'] for n in sg.nodes()]\n",
    "    \n",
    "    attachment_numbers_r = np.random.geometric(1/attachment_number_mean, size=wide_bridge_size)\n",
    "    attachment_numbers_b = np.random.geometric(1/attachment_number_mean, size=wide_bridge_size)\n",
    "\n",
    "    pa_r = [x[1] for x in sg1.degree]/np.sum([x[1] for x in sg1.degree])\n",
    "    pa_b = [x[1] for x in sg2.degree]/np.sum([x[1] for x in sg2.degree])\n",
    "\n",
    "    def to_boolean_array(size, indices):\n",
    "        res = np.zeros(size)\n",
    "        res[indices] = 1\n",
    "        return res\n",
    "\n",
    "    attachments_r =  np.array([to_boolean_array(cluster_r_size,choice(cluster_r_size, x, p=pa_r)) for x in attachment_numbers_r])\n",
    "    attachments_b =  np.array([to_boolean_array(cluster_b_size,choice(cluster_b_size, x, p=pa_b)) for x in attachment_numbers_b])\n",
    "\n",
    "    inter_bridge_attachments = np.random.binomial(1, inter_bridge_connection_prob, size=(wide_bridge_size,wide_bridge_size))\n",
    "    \n",
    "    new_edges = [(x,cluster_r_size+cluster_b_size+y) for x in range(cluster_r_size) for y in range(wide_bridge_size) if attachments_r.T[x,y]] \n",
    "    new_edges += [(cluster_r_size+x,cluster_r_size+cluster_b_size+y) for x in range(cluster_b_size) for y in range(wide_bridge_size) if attachments_b.T[x,y]]\n",
    "    new_edges += [(cluster_r_size+cluster_b_size+x,cluster_r_size+cluster_b_size+y) for x in range(wide_bridge_size) for y in range(wide_bridge_size) if inter_bridge_attachments.T[x,y]]\n",
    "\n",
    "    sg_res = sg.copy()\n",
    "    sg_res.add_edges_from(new_edges)\n",
    "    return sg_res, colors\n",
    "\n",
    "\n",
    "sg_2, colors_2 = generate_graph_with_attachments(2, 0.05, 10, 10, 3)\n",
    "sg_3, colors_3 = generate_graph_with_attachments(2, 0.05, 50, 50, 3)\n",
    "sg_4, colors_4 = generate_graph_with_attachments(2, 0.05, 100, 100, 3)\n",
    "sg_5, colors_5 = generate_graph_with_attachments(1, 0.05, 50, 50, 40)\n",
    "sg_6, colors_6 = generate_graph_with_attachments(5, 0.1)\n",
    "\n",
    "graphs_and_colors = [(1, sg_1, colors_1),(2, sg_2, colors_2),(3, sg_3, colors_3),(4, sg_4, colors_4),(5, sg_5, colors_5),(6, sg_6, colors_6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph, colors in graphs_and_colors:\n",
    "    with open('graph_'+str(i)+'.txt','wb') as f:\n",
    "        for line in nx.to_numpy_matrix(graph):\n",
    "            np.savetxt(f, line, fmt='%.2f')\n",
    "    with open('colors_'+str(i)+'.txt', 'w') as f:\n",
    "        for color in colors:\n",
    "            f.write(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cascade(graph_t, source):\n",
    "    graph = graph_t.copy()\n",
    "    graph_size = len(graph.nodes)\n",
    "    r = np.random.weibull(2, (graph_size, graph_size))\n",
    "    s = np.random.uniform(size=(graph_size, graph_size))\n",
    "    tau = -1*np.log(s)/r\n",
    "    tau = np.multiply((nx.to_numpy_matrix(graph)), tau)\n",
    "\n",
    "    graph.add_weighted_edges_from([(x,y,tau[x,y]) for x in range(graph_size) for y in range(graph_size) if tau[x,y] > 0])\n",
    "    \n",
    "    source = source\n",
    "    branching = nx.shortest_path(graph, source, weight='weight')\n",
    "    timings = nx.shortest_path_length(graph, source, weight='weight')\n",
    "    \n",
    "    return (branching, timings)\n",
    "\n",
    "def generate_path_from_prev(prev_dict, mem, u):\n",
    "    if u in mem:\n",
    "        return mem[u], mem\n",
    "    else:\n",
    "        if prev_dict[u] is not None:\n",
    "            new_path, new_mem = generate_path_from_prev(prev_dict, mem, prev_dict[u])\n",
    "            mem[u] = new_path + [u]\n",
    "            return mem[u], mem\n",
    "        else:\n",
    "            mem[u] = [u]\n",
    "            return [u], mem\n",
    "    \n",
    "def generate_paths(prev_dict, source):\n",
    "    #returns paths for u, with updated dict\n",
    "    mem = {}\n",
    "    for u in prev_dict.keys():\n",
    "        generate_path_from_prev(prev_dict, mem, u)\n",
    "    for k in prev_dict.keys():\n",
    "        if prev_dict[k] is None and k != source:\n",
    "            del mem[k]\n",
    "    return mem\n",
    "\n",
    "def shortest_path(graph, source):\n",
    "    q = OrderedDict()\n",
    "    prev = {}\n",
    "    timings = {}\n",
    "    for v in graph.nodes():\n",
    "        q[v] = float('inf')\n",
    "        timings[v] = None\n",
    "        prev[v] = None\n",
    "    q[source] = 0\n",
    "    timings[source] = 0\n",
    "    while q != {}:\n",
    "        q = OrderedDict(sorted(q.items(), key=lambda x: x[1], reverse=True))\n",
    "        u, d = q.popitem()\n",
    "        for v in graph.neighbors(u):\n",
    "            if v in q.keys():\n",
    "                alt = d + graph[u][v]['weight']\n",
    "                if alt < q[v]:\n",
    "                    q[v] = alt\n",
    "                    prev[v] = u\n",
    "                    timings[v] = alt\n",
    "    return timings, prev\n",
    "\n",
    "def complex_shortest_path(graph, source, complex_criteria, sus):\n",
    "    q = OrderedDict() #Essentially a queue of infected waiting to infect\n",
    "    prev = {}\n",
    "    timings = {} # Time till first infection\n",
    "    infected = set()\n",
    "    for v in graph.nodes():\n",
    "        timings[v] = float('inf')\n",
    "        prev[v] = None\n",
    "    q[source] = 0 # Enqueue the start note //\n",
    "    infected.add(source) #Infect the source\n",
    "    timings[source] = 0 \n",
    "    while q != {}:\n",
    "        q = OrderedDict(sorted(q.items(), key=lambda x: x[1], reverse=True))\n",
    "        u, d = q.popitem() #Dequeue an infected node, with respect to how quickly it was infected\n",
    "        for v in graph.neighbors(u):\n",
    "            if v not in infected:\n",
    "                alt = d + graph[u][v]['weight']\n",
    "                criteria, sus = complex_criteria(v, infected, sus)\n",
    "                if criteria:\n",
    "                    q[v] = alt\n",
    "                    timings[v] = alt\n",
    "                    prev[v] = u\n",
    "                    infected.add(v)\n",
    "    return timings, prev\n",
    "\n",
    "# Rohit's original hard criteria version\n",
    "def complex_generate_cascade_with_hard(graph_t, source, limit=3):\n",
    "    graph = graph_t.copy()\n",
    "    graph_size = len(graph.nodes)\n",
    "    r = np.random.weibull(2, (graph_size, graph_size))\n",
    "    s = np.random.uniform(size=(graph_size, graph_size))\n",
    "    tau = -1*np.log(s)/r\n",
    "    tau = np.multiply((nx.to_numpy_matrix(graph)), tau)\n",
    "    \n",
    "    sus = np.random.uniform(0,limit, graph_size)\n",
    "    \n",
    "    graph.add_weighted_edges_from([(x,y,tau[x,y]) for x in range(graph_size) for y in range(graph_size) if tau[x,y] > 0])\n",
    "    \n",
    "    def complex_criteria(node,infected, sus=sus, graph = graph):\n",
    "        return sum([1 for n in graph.neighbors(node) if n in infected]) > sus[node], sus\n",
    "    \n",
    "    source = source\n",
    "    timings, prev = complex_shortest_path(graph, source, complex_criteria, sus)\n",
    "    branching = generate_paths(prev, source)\n",
    "    for k in prev.keys():\n",
    "        if timings[k] == float('inf'):\n",
    "            del timings[k]\n",
    "    \n",
    "    return (branching, timings)\n",
    "\n",
    "# Andrei's version of complex contagion\n",
    "def complex_generate_cascade_with_prob(graph_t, source, gamma=0.1):\n",
    "    graph = graph_t.copy()\n",
    "    graph_size = len(graph.nodes)\n",
    "    r = np.random.weibull(2, (graph_size, graph_size))\n",
    "    s = np.random.uniform(size=(graph_size, graph_size))\n",
    "    tau = -1*np.log(s)/r\n",
    "    tau = np.multiply((nx.to_numpy_matrix(graph)), tau)\n",
    "    \n",
    "    sus = np.random.uniform(0,1, graph_size)\n",
    "    \n",
    "    graph.add_weighted_edges_from([(x,y,tau[x,y]) for x in range(graph_size) for y in range(graph_size) if tau[x,y] > 0])\n",
    "    \n",
    "    def complex_criteria(node,infected, sus=sus, graph = graph, gamma=gamma):\n",
    "        sus[node] += gamma\n",
    "        sus[node] = min(1, sus[node])\n",
    "        if node in infected:\n",
    "            return True, sus\n",
    "        chance = np.random.binomial(1,sus[node])\n",
    "        return chance == 1, sus\n",
    "    \n",
    "    source = source\n",
    "    timings, prev = complex_shortest_path(graph, source, complex_criteria, sus)\n",
    "    branching = generate_paths(prev, source)\n",
    "    for k in prev.keys():\n",
    "        if timings[k] == float('inf'):\n",
    "            del timings[k]\n",
    "    \n",
    "    return (branching, timings)\n",
    "\n",
    "# Uses the fraction of the friends infected as the criteria\n",
    "def complex_generate_cascade_with_ltm(graph_t, source):\n",
    "    graph = graph_t.copy()\n",
    "    graph_size = len(graph.nodes)\n",
    "    r = np.random.weibull(2, (graph_size, graph_size))\n",
    "    s = np.random.uniform(size=(graph_size, graph_size))\n",
    "    tau = -1*np.log(s)/r\n",
    "    tau = np.multiply((nx.to_numpy_matrix(graph)), tau)\n",
    "    \n",
    "    sus = np.random.uniform(0,1, graph_size)\n",
    "    \n",
    "    graph.add_weighted_edges_from([(x,y,tau[x,y]) for x in range(graph_size) for y in range(graph_size) if tau[x,y] > 0])\n",
    "    \n",
    "    def complex_criteria(node,infected, sus=sus, graph = graph):\n",
    "        return np.mean([(1 if n in infected else 0) for n in graph.neighbors(node)]) > sus[node], sus\n",
    "    \n",
    "    source = source\n",
    "    timings, prev = complex_shortest_path(graph, source, complex_criteria, sus)\n",
    "    branching = generate_paths(prev, source)\n",
    "    for k in prev.keys():\n",
    "        if timings[k] == float('inf'):\n",
    "            del timings[k]\n",
    "    \n",
    "    return (branching, timings)\n",
    "\n",
    "def does_cross_bridge(cascade, colors):\n",
    "    argmin = (lambda d: min(d, key=d.get))\n",
    "    source = argmin(cascade[1])\n",
    "    if colors[source] == 'g':\n",
    "        return False\n",
    "    not_source_color = 'r' if colors[source] == 'b' else 'b'\n",
    "    return any([colors[node] == not_source_color  for node in cascade[1].keys()])\n",
    "            \n",
    "def generate_single_cascade(graph, colors, complex_method='Prob', does_cross=True, single_source=None, params={'limit':3, 'gamma':0.1}):\n",
    "    # The options for the complex contagion method are None, 'Hard', 'Prob' and 'LTM'\n",
    "    MAX_ITER = 1000\n",
    "    counter = 0\n",
    "    while counter < MAX_ITER:\n",
    "        if single_source is None:\n",
    "            graph_size = len(graph.nodes)\n",
    "            source = np.random.randint(graph_size-1)\n",
    "        else:\n",
    "            source = single_source\n",
    "        counter += 1\n",
    "        if complex_method is None:\n",
    "            gen_cas = generate_cascade\n",
    "        elif complex_method == 'Hard' and 'limit' in params:\n",
    "            gen_cas = complex_generate_cascade_with_hard\n",
    "            args = {'limit' : params['limit']}\n",
    "        elif complex_method == 'Prob' and 'gamma' in params:\n",
    "            gen_cas = complex_generate_cascade_with_prob\n",
    "            args = {'gamma' : params['gamma']}\n",
    "        elif complex_method == 'LTM':\n",
    "            gen_cas = complex_generate_cascade_with_ltm\n",
    "            args = {}\n",
    "        else:\n",
    "            raise Exception('Not a valid contagion method and/or parameter')\n",
    "        cas = gen_cas(graph, source, **args)\n",
    "        if not does_cross:\n",
    "            return cas\n",
    "        if does_cross and does_cross_bridge(cas, colors):\n",
    "            return cas\n",
    "    logging.warning('Max Iterations exceeded when generating cascades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades = [generate_single_cascade(graph, colors) for _ in range(number_of_cascades)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('example_cascades.json', 'w')\n",
    "json.dump([{'branching': cas[0], 'timing': cas[1]} for cas in cascades], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
